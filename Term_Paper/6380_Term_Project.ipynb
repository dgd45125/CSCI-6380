{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Donald Dunagan\n",
    "#811-648-053\n",
    "#28 July 2018\n",
    "#CSCI 6380 Term Project\n",
    "#Extending the tracking of Parkinson’s symptoms \n",
    "#through telemonitored speech samples via advanced statistical methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import make_scorer, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataframe is: (5875, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject#</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>test_time</th>\n",
       "      <th>motor_UPDRS</th>\n",
       "      <th>total_UPDRS</th>\n",
       "      <th>Jitter(%)</th>\n",
       "      <th>Jitter(Abs)</th>\n",
       "      <th>Jitter:RAP</th>\n",
       "      <th>Jitter:PPQ5</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer(dB)</th>\n",
       "      <th>Shimmer:APQ3</th>\n",
       "      <th>Shimmer:APQ5</th>\n",
       "      <th>Shimmer:APQ11</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>28.199</td>\n",
       "      <td>34.398</td>\n",
       "      <td>0.00662</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.00401</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.01438</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>0.01662</td>\n",
       "      <td>0.04314</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>21.640</td>\n",
       "      <td>0.41888</td>\n",
       "      <td>0.54842</td>\n",
       "      <td>0.16006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>12.6660</td>\n",
       "      <td>28.447</td>\n",
       "      <td>34.894</td>\n",
       "      <td>0.00300</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>0.00150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179</td>\n",
       "      <td>0.00994</td>\n",
       "      <td>0.01072</td>\n",
       "      <td>0.01689</td>\n",
       "      <td>0.02982</td>\n",
       "      <td>0.011112</td>\n",
       "      <td>27.183</td>\n",
       "      <td>0.43493</td>\n",
       "      <td>0.56477</td>\n",
       "      <td>0.10810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>19.6810</td>\n",
       "      <td>28.695</td>\n",
       "      <td>35.389</td>\n",
       "      <td>0.00481</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181</td>\n",
       "      <td>0.00734</td>\n",
       "      <td>0.00844</td>\n",
       "      <td>0.01458</td>\n",
       "      <td>0.02202</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>23.047</td>\n",
       "      <td>0.46222</td>\n",
       "      <td>0.54405</td>\n",
       "      <td>0.21014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6470</td>\n",
       "      <td>28.905</td>\n",
       "      <td>35.810</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.00264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.01106</td>\n",
       "      <td>0.01265</td>\n",
       "      <td>0.01963</td>\n",
       "      <td>0.03317</td>\n",
       "      <td>0.027837</td>\n",
       "      <td>24.445</td>\n",
       "      <td>0.48730</td>\n",
       "      <td>0.57794</td>\n",
       "      <td>0.33277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6420</td>\n",
       "      <td>29.187</td>\n",
       "      <td>36.375</td>\n",
       "      <td>0.00335</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.00130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.00679</td>\n",
       "      <td>0.00929</td>\n",
       "      <td>0.01819</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>26.126</td>\n",
       "      <td>0.47188</td>\n",
       "      <td>0.56122</td>\n",
       "      <td>0.19361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject#  age  sex  test_time  motor_UPDRS  total_UPDRS  Jitter(%)  \\\n",
       "0         1   72    0     5.6431       28.199       34.398    0.00662   \n",
       "1         1   72    0    12.6660       28.447       34.894    0.00300   \n",
       "2         1   72    0    19.6810       28.695       35.389    0.00481   \n",
       "3         1   72    0    25.6470       28.905       35.810    0.00528   \n",
       "4         1   72    0    33.6420       29.187       36.375    0.00335   \n",
       "\n",
       "   Jitter(Abs)  Jitter:RAP  Jitter:PPQ5   ...     Shimmer(dB)  Shimmer:APQ3  \\\n",
       "0     0.000034     0.00401      0.00317   ...           0.230       0.01438   \n",
       "1     0.000017     0.00132      0.00150   ...           0.179       0.00994   \n",
       "2     0.000025     0.00205      0.00208   ...           0.181       0.00734   \n",
       "3     0.000027     0.00191      0.00264   ...           0.327       0.01106   \n",
       "4     0.000020     0.00093      0.00130   ...           0.176       0.00679   \n",
       "\n",
       "   Shimmer:APQ5  Shimmer:APQ11  Shimmer:DDA       NHR     HNR     RPDE  \\\n",
       "0       0.01309        0.01662      0.04314  0.014290  21.640  0.41888   \n",
       "1       0.01072        0.01689      0.02982  0.011112  27.183  0.43493   \n",
       "2       0.00844        0.01458      0.02202  0.020220  23.047  0.46222   \n",
       "3       0.01265        0.01963      0.03317  0.027837  24.445  0.48730   \n",
       "4       0.00929        0.01819      0.02036  0.011625  26.126  0.47188   \n",
       "\n",
       "       DFA      PPE  \n",
       "0  0.54842  0.16006  \n",
       "1  0.56477  0.10810  \n",
       "2  0.54405  0.21014  \n",
       "3  0.57794  0.33277  \n",
       "4  0.56122  0.19361  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import Parkinson's Dataset and visualize\n",
    "\n",
    "PDDF =  pd.read_csv(\"C:\\\\Users\\\\gray\\\\Desktop\\\\CSCI6380\\\\Term_Paper\\\\Parkinson's_Data.csv\")\n",
    "print ('The shape of the dataframe is:',PDDF.shape)\n",
    "PDDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial shuffling and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data\n",
    "PDDF = shuffle(PDDF)\n",
    "\n",
    "#isolate features\n",
    "features_to_drop = ['subject#','age','sex','test_time','motor_UPDRS','total_UPDRS']\n",
    "just_features = PDDF.drop(features_to_drop,axis=1)\n",
    "    \n",
    "#isolate motor_UPDRS\n",
    "just_motor = PDDF.motor_UPDRS\n",
    "   \n",
    "#isolate total_UPDRS\n",
    "just_total = PDDF.total_UPDRS\n",
    "\n",
    "#split into training and testing data\n",
    "training_features = just_features[:5287]\n",
    "testing_features = just_features[5287:]\n",
    "    \n",
    "training_motor = just_motor[:5287]\n",
    "testing_motor = just_motor[5287:]\n",
    "    \n",
    "training_total = just_total[:5287]\n",
    "testing_total = just_total[5287:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function for shuffling and splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleSplit():\n",
    "    '''\n",
    "    Shuffles and splits the DataFrame     \n",
    "    '''\n",
    "    global PDDF\n",
    "    \n",
    "    #shuffle the data\n",
    "    PDDF = shuffle(PDDF)\n",
    "\n",
    "    #isolate features\n",
    "    features_to_drop = ['subject#','age','sex','test_time','motor_UPDRS','total_UPDRS']\n",
    "    global just_features\n",
    "    just_features = PDDF.drop(features_to_drop,axis=1)\n",
    "    \n",
    "    #isolate motor_UPDRS\n",
    "    global just_motor\n",
    "    just_motor = PDDF.motor_UPDRS\n",
    "   \n",
    "    #isolate total_UPDRS\n",
    "    global just_total\n",
    "    just_total = PDDF.total_UPDRS\n",
    "\n",
    "    #split into training and testing data\n",
    "    global training_features\n",
    "    training_features = just_features[:5287]\n",
    "    global testing_features\n",
    "    testing_features = just_features[5287:]\n",
    "    \n",
    "    global training_motor\n",
    "    training_motor = just_motor[:5287]\n",
    "    global testing_motor\n",
    "    testing_motor = just_motor[5287:]\n",
    "    \n",
    "    global training_total\n",
    "    training_total = just_total[:5287]\n",
    "    global testing_total\n",
    "    testing_total = just_total[5287:]  \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cross validation needs to return the mean absolute error (MAE) for each fold\n",
    "#so i have to make a custom scoring object\n",
    "\n",
    "#create scorer object\n",
    "myScorer = make_scorer(mean_absolute_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CARTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get baselines for untuned trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned CART targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.601175357581009\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned regression tree targeting motor_UPDRS\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(tree,training_features,training_motor,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned CART targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.68000020244386\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned regression tree targeting total_UPDRS\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(tree,training_features,training_total,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunable parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'presort': False,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regression tree parameters which can be tuned\n",
    "tree = DecisionTreeRegressor()\n",
    "print(\"Tunable parameters: \")\n",
    "tree.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning CART targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_leaf_nodes': 80}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal number of leaf nodes\n",
    "paramsToTune = {\n",
    "    'max_leaf_nodes': [80, 85, 90, 95, 100],\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_depth': 6.0}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal max depth\n",
    "paramsToTune = {\n",
    "    'max_depth': np.linspace(1,10,10, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'min_samples_split': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal minimum split\n",
    "paramsToTune = {\n",
    "    'min_samples_split':np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'min_samples_leaf': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal minimum leaf size\n",
    "paramsToTune = {\n",
    "    'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_features': 15}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal max number of features\n",
    "paramsToTune = {\n",
    "        'max_features': [10,11,12,13,14,15,16]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_features': 11, 'max_leaf_nodes': 140}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'max_depth': [2,3,4,5,6,7],\n",
    "    'max_leaf_nodes':[130,140,150,160,170,180,190],\n",
    "    'max_features': [10,11,12,13,14,15,16]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print (GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of a tuned CART targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuned CART has a 10-fold CV'd training motor_UPDRS MAE of 6.067455367559535\n"
     ]
    }
   ],
   "source": [
    "#train a CART with these tuned hyperparameters\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=5,max_features=11,max_leaf_nodes=140)\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(tree,training_features,training_motor,cv=10,scoring=myScorer)\n",
    "print(\"The tuned CART has a 10-fold CV'd training motor_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning CART targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_leaf_nodes': 80}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal number of leaf nodes\n",
    "paramsToTune = {\n",
    "    'max_leaf_nodes': [80, 85, 90, 95, 100],\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_depth': 6.0}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal max depth\n",
    "paramsToTune = {\n",
    "    'max_depth': np.linspace(1,10,10, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS= GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'min_samples_split': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal minimum split\n",
    "paramsToTune = {\n",
    "    'min_samples_split':np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'min_samples_leaf': 0.1}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal minimum leaf size\n",
    "paramsToTune = {\n",
    "    'min_samples_leaf': np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_features': 11}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to approximate optimal max number of features\n",
    "paramsToTune = {\n",
    "        'max_features': [10,11,12,13,14,15,16]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'max_features': 14, 'max_leaf_nodes': 40}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic CART and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'max_depth': [4,5,6,7,8,9,10,11],\n",
    "    'max_leaf_nodes':[20,30,40,50,60],\n",
    "    'max_features': [12,13,14,15,16]\n",
    "}\n",
    "\n",
    "tree = DecisionTreeRegressor()\n",
    "GS = GridSearchCV(estimator=tree, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print (GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of a tuned CART targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuned CART has a 10-fold CV'd training training_total MAE of 7.673857197177156\n"
     ]
    }
   ],
   "source": [
    "#train a CART with these tuned hyperparameters\n",
    "\n",
    "tree = DecisionTreeRegressor(max_depth=7,max_features=14,max_leaf_nodes=40)\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(tree,training_features,training_total,cv=10,scoring=myScorer)\n",
    "print(\"The tuned CART has a 10-fold CV'd training training_total MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "- Shuffle the data and split into training and testing (90%-10%)\n",
    "- Fit the tuned CART to the training data and then calculate testing MAE on the test data\n",
    "- Repeat 1,000 times, logging the MAE for each repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned CART targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorCartErrs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train a CART tree with the tuned hyperparameters\n",
    "    tree = DecisionTreeRegressor(max_depth=5,max_features=11,max_leaf_nodes=140)\n",
    "    tree.fit(training_features,training_motor)\n",
    "    #make predictions\n",
    "    predicts = tree.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    motorCartErrs.append(mean_absolute_error(predicts,testing_motor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stats' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0c34c803d46f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mconfInterval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.65\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmotorCartErrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmotorCartErrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmotorCartErrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mconfInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"After 1,000 testing runs, the test MAE for total_UPDRS is {} ± {} points\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmotorCartErrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stats' is not defined"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(motorCartErrs), scale=np.std(motorCartErrs))\n",
    "val = np.mean(motorCartErrs)-confInterval[0]\n",
    "print(\"After 1,000  runs, the test MAE for motor_UPDRS is {} ± {} points\".format(np.mean(motorCartErrs),val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned CART targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCartErrs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train a CART tree with the tuned hyperparameters\n",
    "    tree = DecisionTreeRegressor(max_depth=7,max_features=14,max_leaf_nodes=40)\n",
    "    tree.fit(training_features,training_total)\n",
    "    #make predictions\n",
    "    predicts = tree.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    totalCartErrs.append(mean_absolute_error(predicts,testing_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1,000 CV runs, the test MAE for total_UPDRS is 7.628095453003876 ± 0.2236975975263613 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(totalCartErrs), scale=np.std(totalCartErrs))\n",
    "val = np.mean(totalCartErrs)-confInterval[0]\n",
    "print(\"After 1,000 CV runs, the test MAE for total_UPDRS is {} ± {} points\".format(np.mean(totalCartErrs),val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get baselines for untuned RFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned RF targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.351676342026837\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned RF targeting motor_UPDRS\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(forest,training_features,training_motor,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned RF targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.845199657966693\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned RF targeting motor_UPDRS\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(forest,training_features,training_total,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunable parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'criterion': 'mse',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RF parameters which can be tuned\n",
    "forest = RandomForestRegressor()\n",
    "print(\"Tunable parameters: \")\n",
    "forest.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RF targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_depth': 100}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max depth\n",
    "paramsToTune = {\n",
    "    'max_depth': [80, 85, 90, 95, 100],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_leaf_nodes': 260}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max number of leaf nodes\n",
    "paramsToTune = {\n",
    "    'max_leaf_nodes': [220,230,240,250,260],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_features': 14}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max number of features\n",
    "paramsToTune = {\n",
    "    'max_features': [11,12,13,14,15,16],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max number of estimators in the forest\n",
    "paramsToTune = {\n",
    "    'n_estimators': [10,50,100],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 65, 'max_features': 16, 'max_leaf_nodes': 250}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'max_depth': [45,50,55,60,65,70,75],\n",
    "    'max_leaf_nodes':[230,240,250,260,270,280,290],\n",
    "    'max_features': [12,13,14,15,16]\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print (GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of a tuned RF targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuned RF has a 10-fold CV'd training motor_UPDRS MAE of 5.33584851115302\n"
     ]
    }
   ],
   "source": [
    "#train an RF with these tuned hyperparameters\n",
    "\n",
    "forest = RandomForestRegressor(max_depth=65,max_features=16,max_leaf_nodes=250,n_estimators=10)\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(forest,training_features,training_motor,cv=10,scoring=myScorer)\n",
    "print(\"The tuned RF has a 10-fold CV'd training motor_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning RF targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_depth': 95}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max depth\n",
    "paramsToTune = {\n",
    "    'max_depth': [80,85,90,95],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_leaf_nodes': 790}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max number of leaf nodes\n",
    "paramsToTune = {\n",
    "    'max_leaf_nodes': [780,790,800,810,820]\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'max_features': 14}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to approximate optimal max number of features\n",
    "paramsToTune = {\n",
    "    'max_features': [11,12,13,14,15,16],\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 20, 'max_features': 15, 'max_leaf_nodes': 650}\n"
     ]
    }
   ],
   "source": [
    "#instantiate a generic RF and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'max_depth': [10,15,20,25,30,35,40],\n",
    "    'max_leaf_nodes':[630,640,650,660,670,680,690],\n",
    "    'max_features': [12,13,14,15,16]\n",
    "}\n",
    "\n",
    "forest = RandomForestRegressor()\n",
    "GS = GridSearchCV(estimator=forest, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print (GS.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of a tuned RF targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tuned RF has a 10-fold CV'd training total_UPDRS MAE of 6.767816367379036\n"
     ]
    }
   ],
   "source": [
    "#train an RF with these tuned hyperparameters\n",
    "\n",
    "forest = RandomForestRegressor(max_depth=20,max_features=15,max_leaf_nodes=650,n_estimators=10)\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(forest,training_features,training_total,cv=10,scoring=myScorer)\n",
    "print(\"The tuned RF has a 10-fold CV'd training total_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "- Shuffle the data and split into training and testing (90%-10%)\n",
    "- Fit the tuned RF to the training data and then calculate testing MAE on the test data\n",
    "- Repeat 100 times, logging the MAE for each repetition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorRfErrs = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train an RF with the tuned hyperparameters\n",
    "    forest = RandomForestRegressor(max_depth=65,max_features=16,max_leaf_nodes=250,n_estimators=100)\n",
    "    forest.fit(training_features,training_motor)\n",
    "    #make predictions\n",
    "    predicts = forest.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    motorRfErrs.append(mean_absolute_error(predicts,testing_motor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 CV runs, the test MAE for motor_UPDRS is 5.17460477239424 ± 0.12504720567955552 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(motorRfErrs), scale=np.std(motorRfErrs))\n",
    "val = np.mean(motorRfErrs)-confInterval[0]\n",
    "print(\"After 100 CV runs, the test MAE for motor_UPDRS is {} ± {} points\".format(np.mean(motorRfErrs),val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuned RF targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalRfErrs = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train an RF with the tuned hyperparameters\n",
    "    forest = RandomForestRegressor(max_depth=20,max_features=15,max_leaf_nodes=650,n_estimators=100)\n",
    "    forest.fit(training_features,training_total)\n",
    "    #make predictions\n",
    "    predicts = forest.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    totalRfErrs.append(mean_absolute_error(predicts,testing_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 CV runs, the test MAE for total_UPDRS is 6.466393946774503 ± 0.20589660842942692 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(totalRfErrs), scale=np.std(totalRfErrs))\n",
    "val = np.mean(totalRfErrs)-confInterval[0]\n",
    "print(\"After 100 CV runs, the test MAE for total_UPDRS is {} ± {} points\".format(np.mean(totalRfErrs),val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaBoosted Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get baselines for untuned ABDTs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned ABDT targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 4.682722270407288\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned ABDT targeting motor_UPDRS\n",
    "\n",
    "abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(abr,training_features,training_motor,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned ABDT targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5.960161880012317\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned ABDT targeting motor_UPDRS\n",
    "\n",
    "abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(abr,training_features,training_total,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunable parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_estimator': None,\n",
       " 'learning_rate': 1.0,\n",
       " 'loss': 'linear',\n",
       " 'n_estimators': 50,\n",
       " 'random_state': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ABDT parameters which can be tuned\n",
    "abr = AdaBoostRegressor()\n",
    "print(\"Tunable parameters: \")\n",
    "abr.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning ABDT targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')}\n"
     ]
    }
   ],
   "source": [
    "#instantiate ABDT and use Grid Search to approximate optimal base estimator\n",
    "paramsToTune = {\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth=1),DecisionTreeRegressor(max_depth=2),DecisionTreeRegressor(max_depth=3),DecisionTreeRegressor(max_depth=4)],\n",
    "}\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "GS = GridSearchCV(estimator=abr, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'learning_rate': 1}\n"
     ]
    }
   ],
   "source": [
    "#instantiate ABDT and use Grid Search to approximate optimal learning rate\n",
    "paramsToTune = {\n",
    "    'learning_rate': [1,2,3,4,5],\n",
    "}\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "GS = GridSearchCV(estimator=abr, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "#instantiate ABDT and use Grid Search to approximate optimal learning rate\n",
    "paramsToTune = {\n",
    "    'n_estimators': [50,100,150],\n",
    "}\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "GS = GridSearchCV(estimator=abr, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'base_estimator': DecisionTreeRegressor(criterion='mse', max_depth=4, max_features=None,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best'), 'learning_rate': 1, 'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "#instantiate ABDT and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'base_estimator': [DecisionTreeRegressor(max_depth=1),DecisionTreeRegressor(max_depth=2),DecisionTreeRegressor(max_depth=3),DecisionTreeRegressor(max_depth=4)],\n",
    "    'learning_rate': [1,2,3],\n",
    "    'n_estimators': [15,20,30]\n",
    "}\n",
    "\n",
    "abr = AdaBoostRegressor()\n",
    "GS = GridSearchCV(estimator=abr, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an ABDT targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ABDT has a 10-fold CV'd training motor_UPDRS MAE of 4.700517960810849\n"
     ]
    }
   ],
   "source": [
    "#train an ABDT\n",
    "\n",
    "abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(abr,training_features,training_motor,cv=10,scoring=myScorer)\n",
    "print(\"The ABDT has a 10-fold CV'd training motor_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an ABDT targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train an ABDT\n",
    "\n",
    "abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(abr,training_features,training_total,cv=10,scoring=myScorer)\n",
    "print(\"The ABDT has a 10-fold CV'd training total_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "- Shuffle the data and split into training and testing (90%-10%)\n",
    "- Fit the tuned ABDT to the training data and then calculate testing MAE on the test data\n",
    "- Repeat 100 times, logging the MAE for each repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorAbdtErrs = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train an ABDT\n",
    "    abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "    abr.fit(training_features,training_motor)\n",
    "    #make predictions\n",
    "    predicts = abr.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    motorAbdtErrs.append(mean_absolute_error(predicts,testing_motor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 CV runs, the test MAE for motor_UPDRS is 4.7014933667656225 ± 0.15777313384950986 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(motorAbdtErrs), scale=np.std(motorAbdtErrs))\n",
    "val = np.mean(motorAbdtErrs)-confInterval[0]\n",
    "print(\"After 100 CV runs, the test MAE for motor_UPDRS is {} ± {} points\".format(np.mean(motorAbdtErrs),val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalAbdtErrs = []\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train an ABDT\n",
    "    abr = AdaBoostRegressor(base_estimator=DecisionTreeRegressor())\n",
    "    abr.fit(training_features,training_total)\n",
    "    #make predictions\n",
    "    predicts = abr.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    totalAbdtErrs.append(mean_absolute_error(predicts,testing_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 100 CV runs, the test MAE for motor_UPDRS is 5.9492480235322125 ± 0.2122657693193828 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(totalAbdtErrs), scale=np.std(totalAbdtErrs))\n",
    "val = np.mean(totalAbdtErrs)-confInterval[0]\n",
    "print(\"After 100 CV runs, the test MAE for total_UPDRS is {} ± {} points\".format(np.mean(totalAbdtErrs),val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, get baselines for untuned KNNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned KNN targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 6.549629210459988\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned KNN targeting motor_UPDRS\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(KNN,training_features,training_motor,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of an untuned KNN targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 8.36904170352151\n"
     ]
    }
   ],
   "source": [
    "#10-fold cross validated untuned KNN targeting motor_UPDRS\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(KNN,training_features,training_total,cv=10, scoring=myScorer)\n",
    "print(\"MAE: {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuneable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tunable parameters: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': 1,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN parameters which can be tuned\n",
    "KNN = KNeighborsRegressor()\n",
    "print(\"Tunable parameters: \")\n",
    "KNN.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning KNN targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal base algorithm\n",
    "paramsToTune = {\n",
    "    'algorithm': ['auto','ball_tree','kd_tree','brute'],\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal weighting\n",
    "paramsToTune = {\n",
    "    'weights': ['uniform','distance'],\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'n_neighbors': 18}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal num_neighbors\n",
    "paramsToTune = {\n",
    "    'n_neighbors': [18,19,20,21,22]\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'algorithm': 'auto', 'n_neighbors': 21, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'n_neighbors': [18,19,20,21,22,],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm': ['auto','ball_tree','kd_tree','brute']\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_motor)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of tuned KNN targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KNN has a 10-fold CV'd training motor_UPDRS MAE of 6.419689539033969\n"
     ]
    }
   ],
   "source": [
    "#train KNN\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors=21,weights='distance')\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(KNN,training_features,training_motor,cv=10,scoring=myScorer)\n",
    "print(\"The KNN has a 10-fold CV'd training motor_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning KNN targeting total_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'algorithm': 'auto'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal base algorithm\n",
    "paramsToTune = {\n",
    "    'algorithm': ['auto','ball_tree','kd_tree','brute'],\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal weighting\n",
    "paramsToTune = {\n",
    "    'weights': ['uniform','distance'],\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'n_neighbors': 19}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to approximate optimal num_neighbors\n",
    "paramsToTune = {\n",
    "    'n_neighbors': [18,19,20,21,22]\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate optimum: {'algorithm': 'auto', 'n_neighbors': 19, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "#instantiate KNN and use Grid Search to find the optimal parameters\n",
    "paramsToTune = {\n",
    "    'n_neighbors': [18,19,20,21,22,],\n",
    "    'weights': ['uniform','distance'],\n",
    "    'algorithm': ['auto','ball_tree','kd_tree','brute']\n",
    "}\n",
    "\n",
    "KNN = KNeighborsRegressor()\n",
    "GS = GridSearchCV(estimator=KNN, param_grid=paramsToTune, cv=10)\n",
    "GS.fit(training_features,training_total)\n",
    "print ('Approximate optimum: {}'.format(GS.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10-fold cross validated training MAE of tuned KNN targeting motor_UPDRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KNN has a 10-fold CV'd training total_UPDRS MAE of 8.100647739120332\n"
     ]
    }
   ],
   "source": [
    "#train KNN\n",
    "\n",
    "KNN = KNeighborsRegressor(n_neighbors=19,weights='distance')\n",
    "\n",
    "#10-fold CV\n",
    "vals = cross_val_score(KNN,training_features,training_total,cv=10,scoring=myScorer)\n",
    "print(\"The KNN has a 10-fold CV'd training total_UPDRS MAE of {}\".format(vals.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "- Shuffle the data and split into training and testing (90%-10%)\n",
    "- Fit the tuned KNN to the training data and then calculate testing MAE on the test data\n",
    "- Repeat 1000 times, logging the MAE for each repetition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "motorKnnErrs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train KNN\n",
    "    KNN = KNeighborsRegressor(n_neighbors=21,weights='distance')\n",
    "    KNN.fit(training_features,training_motor)\n",
    "    #make predictions\n",
    "    predicts = KNN.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    motorKnnErrs.append(mean_absolute_error(predicts,testing_motor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1,000 CV runs, the test MAE for motor_UPDRS is 6.380328352912919 ± 0.15703171816412986 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(motorKnnErrs), scale=np.std(motorKnnErrs))\n",
    "val = np.mean(motorKnnErrs)-confInterval[0]\n",
    "print(\"After 1,000 CV runs, the test MAE for motor_UPDRS is {} ± {} points\".format(np.mean(motorKnnErrs),val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalKnnErrs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    #shuffle the data\n",
    "    shuffleSplit()\n",
    "    \n",
    "    #train KNN\n",
    "    KNN = KNeighborsRegressor(n_neighbors=19,weights='distance')\n",
    "    KNN.fit(training_features,training_total)\n",
    "    #make predictions\n",
    "    predicts = KNN.predict(testing_features)\n",
    "\n",
    "    #calculate MAE and add to list of errors\n",
    "    totalKnnErrs.append(mean_absolute_error(predicts,testing_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 1,000 CV runs, the test MAE for motor_UPDRS is 8.061919189090547 ± 0.2129532679595556 points\n"
     ]
    }
   ],
   "source": [
    "confInterval = stats.norm.interval(0.65, loc=np.mean(totalKnnErrs), scale=np.std(totalKnnErrs))\n",
    "val = np.mean(totalKnnErrs)-confInterval[0]\n",
    "print(\"After 1,000 CV runs, the test MAE for total_UPDRS is {} ± {} points\".format(np.mean(totalKnnErrs),val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
